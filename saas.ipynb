{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/digiartbytes/digiartbytes/blob/main/saas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zoOJMitOlgq0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5ISKpSqlmIR"
      },
      "source": [
        "Make a SAAS Software and Deploy (Task Based) Examples Taken from Autogen Documentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcY2XojRlnvc",
        "outputId": "c27abbfb-7c36-4626-b49f-ce9b77c8c798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import shutil, os, subprocess\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "os.chdir('/content/drive/My Drive/YouTube/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyautogen docker chromadb tiktoken openai pypdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aCYg4KtqFkJ",
        "outputId": "4b0d6ac0-aee5-4406-fdbd-3a4637984def"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyautogen\n",
            "  Downloading pyautogen-0.1.14-py3-none-any.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker\n",
            "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromadb\n",
            "  Downloading chromadb-0.4.15-py3-none-any.whl (479 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.8/479.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.1.1-py3-none-any.whl (217 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.8/217.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf\n",
            "  Downloading pypdf-3.17.0-py3-none-any.whl (277 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.4/277.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from pyautogen) (5.6.3)\n",
            "Collecting flaml (from pyautogen)\n",
            "  Downloading FLAML-2.1.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.2/295.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv (from pyautogen)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.3.0)\n",
            "Requirement already satisfied: packaging>=14.0 in /usr/local/lib/python3.10/dist-packages (from docker) (23.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker) (2.31.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker) (2.0.7)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker) (1.6.4)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.10.13)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.5.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.20.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.20.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.20.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.59.2)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-28.1.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.5.0 (from chromadb)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (6.0.1)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.17.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Collecting urllib3>=1.26.0 (from docker)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (6.8.0)\n",
            "Collecting backoff<3.0.0,>=1.10.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.61.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.20.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.20.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.20.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.20.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-semantic-conventions==0.41b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.41b0-py3-none-any.whl (26 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker) (3.4)\n",
            "Collecting huggingface_hub<0.18,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.1.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb) (1.14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=cfd39b95cb35af46c3e3e04e9ab5ce050d24e20e935d258a29eb7d1a73fa7e43\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, websockets, uvloop, urllib3, typing-extensions, python-dotenv, pypdf, pulsar-client, overrides, opentelemetry-semantic-conventions, opentelemetry-proto, humanfriendly, httptools, h11, flaml, deprecated, chroma-hnswlib, bcrypt, backoff, watchfiles, uvicorn, starlette, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, tiktoken, posthog, opentelemetry-sdk, openai, onnxruntime, huggingface_hub, fastapi, docker, tokenizers, pyautogen, opentelemetry-exporter-otlp-proto-grpc, kubernetes, chromadb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-4.0.1 chroma-hnswlib-0.7.3 chromadb-0.4.15 coloredlogs-15.0.1 deprecated-1.2.14 docker-6.1.3 fastapi-0.104.1 flaml-2.1.1 h11-0.14.0 httptools-0.6.1 huggingface_hub-0.17.3 humanfriendly-10.0 kubernetes-28.1.0 monotonic-1.6 onnxruntime-1.16.1 openai-0.28.1 opentelemetry-api-1.20.0 opentelemetry-exporter-otlp-proto-common-1.20.0 opentelemetry-exporter-otlp-proto-grpc-1.20.0 opentelemetry-proto-1.20.0 opentelemetry-sdk-1.20.0 opentelemetry-semantic-conventions-0.41b0 overrides-7.4.0 posthog-3.0.2 pulsar-client-3.3.0 pyautogen-0.1.14 pypdf-3.17.0 pypika-0.48.9 python-dotenv-1.0.0 starlette-0.27.0 tiktoken-0.5.1 tokenizers-0.14.1 typing-extensions-4.8.0 urllib3-1.26.18 uvicorn-0.24.0.post1 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZB7CVdG6HV5X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read JSON file (No Need for End User)\n",
        "import json\n",
        "with open('myconfig.json') as data_file:\n",
        "  myconfig = json.load(data_file)\n",
        "print(myconfig.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VywXf-1EoBIL",
        "outputId": "b38c57ba-08dd-46f4-c87f-f8d054d2d886"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['OPEN_API_KEY', 'OPENAI_API_KEY', 'DB_HOST', 'DB_PORT', 'DB_USER', 'DB_PASSWORD', 'HF_TOKEN'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OAI_CONFIG_LIST = [\n",
        "    {\n",
        "        \"model\": \"gpt-4\",\n",
        "        \"api_key\": myconfig['OPENAI_API_KEY']  #### Pls set your openai_key directly here\n",
        "    }\n",
        "]\n",
        "os.environ['OAI_CONFIG_LIST'] = json.dumps(OAI_CONFIG_LIST)"
      ],
      "metadata": {
        "id": "9BkiLrUwHWXd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjIdYHvPNL86",
        "outputId": "53f25e54-5f2d-491e-91a3-d0489a6a7417"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/YouTube\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HRukHAGSNS3W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import autogen\n",
        "\n",
        "llm_config={\n",
        "    \"request_timeout\": 300,\n",
        "    \"seed\": 44,  # change the seed for different trials\n",
        "    \"config_list\": autogen.config_list_from_json(\n",
        "        \"OAI_CONFIG_LIST\",\n",
        "        filter_dict={\"model\": [\"gpt-4\"]},\n",
        "    ),\n",
        "    \"temperature\": 0,\n",
        "}"
      ],
      "metadata": {
        "id": "GdnRVjqhpVN-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an AssistantAgent instance named \"assistant\"\n",
        "assistant = autogen.AssistantAgent(\n",
        "    name=\"assistant\",\n",
        "    llm_config=llm_config,\n",
        "    is_termination_msg=lambda x: True if \"TERMINATE\" in x.get(\"content\") else False,\n",
        ")\n",
        "# create a UserProxyAgent instance named \"user_proxy\"\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"user_proxy\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=lambda x: True if \"TERMINATE\" in x.get(\"content\") else False,\n",
        "    max_consecutive_auto_reply=10,\n",
        "    code_execution_config={\n",
        "        \"work_dir\": \"work_dir\",\n",
        "        \"use_docker\": False,\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "DKwKTF-sNaW5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task1 = \"\"\"\n",
        "Create a Python program to monitor if the web sites is live\n",
        "use these web site urls :\n",
        "https://en.wikipedia.org/wiki/ChatGPT\n",
        "https://en.wikipedia.org/wiki/GPT-4\n",
        "\"\"\"\n",
        "\n",
        "user_proxy.initiate_chat(assistant, message=task1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfb5VNLDNffp",
        "outputId": "b21d4a09-ad44-46da-d428-5e4257b4ac91"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_proxy (to assistant):\n",
            "\n",
            "\n",
            "Create a Python program to monitor if the web sites is live\n",
            "use these web site urls :\n",
            "https://en.wikipedia.org/wiki/ChatGPT\n",
            "https://en.wikipedia.org/wiki/GPT-4\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to user_proxy):\n",
            "\n",
            "Sure, we can use the `requests` library in Python to send a HTTP request to the websites and check the status code. If the status code is 200, it means the website is live. If not, the website is not live.\n",
            "\n",
            "Here is the Python code:\n",
            "\n",
            "```python\n",
            "# filename: website_monitor.py\n",
            "\n",
            "import requests\n",
            "\n",
            "websites = [\"https://en.wikipedia.org/wiki/ChatGPT\", \"https://en.wikipedia.org/wiki/GPT-4\"]\n",
            "\n",
            "for website in websites:\n",
            "    try:\n",
            "        response = requests.get(website)\n",
            "        if response.status_code == 200:\n",
            "            print(f\"The website {website} is live.\")\n",
            "        else:\n",
            "            print(f\"The website {website} is not live. Status code: {response.status_code}\")\n",
            "    except requests.ConnectionError:\n",
            "        print(f\"Failed to connect to {website}\")\n",
            "```\n",
            "\n",
            "You can run this script by saving it to a file named `website_monitor.py` and then running `python website_monitor.py` in your terminal.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\n",
            "user_proxy (to assistant):\n",
            "\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: \n",
            "The website https://en.wikipedia.org/wiki/ChatGPT is live.\n",
            "The website https://en.wikipedia.org/wiki/GPT-4 is live.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to user_proxy):\n",
            "\n",
            "Great! The code has successfully checked the status of the websites and they are both live. \n",
            "\n",
            "If you want to continuously monitor these websites, you can put the code in a loop and add a delay. However, please be aware that making too many requests to a website in a short period of time can be seen as a denial-of-service attack and may get your IP address blocked by the website.\n",
            "\n",
            "If you have any other tasks or need further assistance, feel free to ask.\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task2 = \"\"\"\n",
        "Help me deploy this program on AWS Lambda and run each 1 minute. Name of the service should be \"pingmelambda\"\n",
        "\n",
        "Dont execute the code\n",
        "\n",
        "\"\"\"\n",
        "user_proxy.initiate_chat(assistant, message=task2, clear_history=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTKis0NiNw5J",
        "outputId": "c3d51731-5265-4158-cc1c-873f2e321a19"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_proxy (to assistant):\n",
            "\n",
            "\n",
            "Help me deploy this program on AWS Lambda and run each 1 minute. Name of the service should be \"pingmelambda\"\n",
            "\n",
            "Dont execute the code\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to user_proxy):\n",
            "\n",
            "Sure, here are the steps to deploy your Python script on AWS Lambda and set it to run every 1 minute. \n",
            "\n",
            "1. **Package your code**: AWS Lambda needs your Python dependencies included in the deployment package. If you have any dependencies, you need to install them in the same directory as your script. In your case, you need the `requests` library. You can create a `requirements.txt` file with the following content:\n",
            "\n",
            "    ```\n",
            "    requests\n",
            "    ```\n",
            "\n",
            "    Then, run the following command to install the dependencies in the current directory:\n",
            "\n",
            "    ```bash\n",
            "    pip install -r requirements.txt -t .\n",
            "    ```\n",
            "\n",
            "    After that, you can create a zip file that includes your Python script and the dependencies:\n",
            "\n",
            "    ```bash\n",
            "    zip -r function.zip .\n",
            "    ```\n",
            "\n",
            "2. **Create a new Lambda function**: Go to the AWS Management Console, navigate to the Lambda service, and create a new function. Name it \"pingmelambda\", choose \"Python 3.8\" as the runtime, and use the \"Create a new role with basic Lambda permissions\" option for the execution role.\n",
            "\n",
            "3. **Upload your code**: In the function code section, choose \"Upload a .zip file\" in the \"Code entry type\" dropdown, and upload the `function.zip` file you created earlier. In the \"Handler\" field, enter the name of your Python script file (without the .py extension) followed by the name of the function you want to execute. For example, if your script is named `website_monitor.py` and the function is named `lambda_handler`, you would enter `website_monitor.lambda_handler`.\n",
            "\n",
            "4. **Set up the trigger**: In the designer section, click on \"Add trigger\", choose \"CloudWatch Events/EventBridge\", and create a new rule. In the rule type section, choose \"Schedule expression\", and enter `rate(1 minute)` to run your function every 1 minute.\n",
            "\n",
            "5. **Save your function**: Click on \"Save\" in the top right corner to save your function.\n",
            "\n",
            "Please note that you need to modify your Python script to work with AWS Lambda. AWS Lambda requires a handler function that takes two arguments: an event, which is the input to your function, and a context, which contains information about the runtime your function is executing in. Here is how you can modify your script:\n",
            "\n",
            "```python\n",
            "import requests\n",
            "\n",
            "def lambda_handler(event, context):\n",
            "    websites = [\"https://en.wikipedia.org/wiki/ChatGPT\", \"https://en.wikipedia.org/wiki/GPT-4\"]\n",
            "\n",
            "    for website in websites:\n",
            "        try:\n",
            "            response = requests.get(website)\n",
            "            if response.status_code == 200:\n",
            "                print(f\"The website {website} is live.\")\n",
            "            else:\n",
            "                print(f\"The website {website} is not live. Status code: {response.status_code}\")\n",
            "        except requests.ConnectionError:\n",
            "            print(f\"Failed to connect to {website}\")\n",
            "```\n",
            "\n",
            "Please replace the existing code with this one and follow the steps above to deploy it on AWS Lambda.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is unknown)...\n",
            "user_proxy (to assistant):\n",
            "\n",
            "exitcode: 1 (execution failed)\n",
            "Code output: \n",
            "unknown language unknown\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to user_proxy):\n",
            "\n",
            "I apologize for the confusion. The instructions provided were not meant to be executed as code, but rather followed as a guide to deploy your Python script on AWS Lambda. \n",
            "\n",
            "Please follow the steps provided in the previous response to deploy your script on AWS Lambda. If you encounter any issues or need further assistance, feel free to ask.\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task3 = \"\"\"\n",
        "Help me deploy this program on AWS Lambda and run each 1 minute. Name of the service should be \"pingmelambda\"\n",
        "\n",
        "Dont execute the code\n",
        "\n",
        "\"\"\"\n",
        "user_proxy.initiate_chat(assistant, message=task3, clear_history=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cxV_6KrO4Mv",
        "outputId": "7d86aa5c-4b02-429b-d492-a32b916bf591"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_proxy (to assistant):\n",
            "\n",
            "\n",
            "Help me deploy this program on AWS Lambda and run each 1 minute. Name of the service should be \"pingmelambda\"\n",
            "\n",
            "Dont execute the code\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to user_proxy):\n",
            "\n",
            "Sure, I can guide you through the process of deploying your Python script on AWS Lambda and setting it to run every 1 minute. \n",
            "\n",
            "1. **Prepare your Python script for AWS Lambda**: AWS Lambda requires a handler function that takes two arguments: an event, which is the input to your function, and a context, which contains information about the runtime your function is executing in. Here is how you can modify your script:\n",
            "\n",
            "```python\n",
            "import requests\n",
            "\n",
            "def lambda_handler(event, context):\n",
            "    websites = [\"https://en.wikipedia.org/wiki/ChatGPT\", \"https://en.wikipedia.org/wiki/GPT-4\"]\n",
            "\n",
            "    for website in websites:\n",
            "        try:\n",
            "            response = requests.get(website)\n",
            "            if response.status_code == 200:\n",
            "                print(f\"The website {website} is live.\")\n",
            "            else:\n",
            "                print(f\"The website {website} is not live. Status code: {response.status_code}\")\n",
            "        except requests.ConnectionError:\n",
            "            print(f\"Failed to connect to {website}\")\n",
            "```\n",
            "\n",
            "2. **Package your code**: AWS Lambda needs your Python dependencies included in the deployment package. If you have any dependencies, you need to install them in the same directory as your script. In your case, you need the `requests` library. You can create a `requirements.txt` file with the following content:\n",
            "\n",
            "    ```\n",
            "    requests\n",
            "    ```\n",
            "\n",
            "    Then, run the following command to install the dependencies in the current directory:\n",
            "\n",
            "    ```bash\n",
            "    pip install -r requirements.txt -t .\n",
            "    ```\n",
            "\n",
            "    After that, you can create a zip file that includes your Python script and the dependencies:\n",
            "\n",
            "    ```bash\n",
            "    zip -r function.zip .\n",
            "    ```\n",
            "\n",
            "3. **Create a new Lambda function**: Go to the AWS Management Console, navigate to the Lambda service, and create a new function. Name it \"pingmelambda\", choose \"Python 3.8\" as the runtime, and use the \"Create a new role with basic Lambda permissions\" option for the execution role.\n",
            "\n",
            "4. **Upload your code**: In the function code section, choose \"Upload a .zip file\" in the \"Code entry type\" dropdown, and upload the `function.zip` file you created earlier. In the \"Handler\" field, enter the name of your Python script file (without the .py extension) followed by the name of the function you want to execute. For example, if your script is named `website_monitor.py` and the function is named `lambda_handler`, you would enter `website_monitor.lambda_handler`.\n",
            "\n",
            "5. **Set up the trigger**: In the designer section, click on \"Add trigger\", choose \"CloudWatch Events/EventBridge\", and create a new rule. In the rule type section, choose \"Schedule expression\", and enter `rate(1 minute)` to run your function every 1 minute.\n",
            "\n",
            "6. **Save your function**: Click on \"Save\" in the top right corner to save your function.\n",
            "\n",
            "Please follow these steps to deploy your script on AWS Lambda. If you encounter any issues or need further assistance, feel free to ask.\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTT1xg14Wjcz+nPjYeI5Vv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}